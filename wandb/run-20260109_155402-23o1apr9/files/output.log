2026-01-09 15:54:03 | INFO | game_rl_training | Loading tokenizer: Qwen/Qwen3-4B
2026-01-09 15:54:04 | INFO | game_rl_training | Loading base model: Qwen/Qwen3-4B
`torch_dtype` is deprecated! Use `dtype` instead!
2026-01-09 15:54:05 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.78it/s]
2026-01-09 15:54:07 | INFO | game_rl_training | Applying LoRA configuration...
2026-01-09 15:54:10 | INFO | root | peft adapter initialised
2026-01-09 15:54:10 | INFO | game_rl_training | Creating reference model...
2026-01-09 15:54:10 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.83it/s]
2026-01-09 15:54:12 | WARNING | root | A <class 'transformers.models.qwen3.modeling_qwen3.Qwen3ForCausalLM'> model is loaded from 'Qwen/Qwen3-4B', and no v_head weight is found. This IS expected if you are not resuming PPO training.
2026-01-09 15:54:12 | INFO | game_rl_training | Initializing PPO trainer...
wandb: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
/root/workplace/game_rl_training/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:262: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.
  warnings.warn(
2026-01-09 15:54:13 | INFO | game_rl_training | Using local OpenSpiel execution (in-process inference, no env server, no vLLM).
2026-01-09 15:54:13 | INFO | game_rl_training | Initializing curriculum sampler...
2026-01-09 15:54:13 | INFO | game_rl_training | Setup complete!
2026-01-09 15:54:13 | INFO | game_rl_training | Starting training...
2026-01-09 15:54:13 | INFO | game_rl_training | Step 1/3000: Collecting rollouts...
2026-01-09 15:56:44 | INFO | game_rl_training | Training...
/root/workplace/game_rl_training/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:1289: UserWarning: KL divergence is starting to become negative: -1.29 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/root/workplace/game_rl_training/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:1289: UserWarning: KL divergence is starting to become negative: -1.48 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
/root/workplace/game_rl_training/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:1289: UserWarning: KL divergence is starting to become negative: -1.30 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.
  warnings.warn(
2026-01-09 16:03:58 | INFO | game_rl_training | Step 2/3000: Collecting rollouts...
2026-01-09 16:06:34 | INFO | game_rl_training | Training...
/root/workplace/game_rl_training/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:1222: UserWarning: The average ratio of batch (11.10) exceeds threshold 10.00. Skipping batch.
  warnings.warn(
