_wandb:
    value:
        cli_version: 0.23.1
        e:
            gmg48429614t9izr64056ihoezcoxhwv:
                codePath: train_ppo_lora.py
                codePathLocal: train_ppo_lora.py
                cpu_count: 22
                cpu_count_logical: 22
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "258907357184"
                        used: "36282912768"
                email: tech.whiz0314@gmail.com
                executable: /root/workplace/game_rl_training/venv/bin/python
                git:
                    commit: b0c092ffe9dd041758f04812b929145ab4864cbc
                    remote: https://github.com/goUp9/game_rl_training.git
                gpu: NVIDIA A100-SXM4-80GB
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100-SXM4-80GB
                      uuid: GPU-abbb1c6e-c8ba-ad2b-4fbf-5460689c2fea
                host: affine-training
                memory:
                    total: "126595055616"
                os: Linux-6.8.0-87-generic-x86_64-with-glibc2.39
                program: /root/workplace/game_rl_training/train_ppo_lora.py
                python: CPython 3.12.3
                root: /root/workplace/game_rl_training
                startedAt: "2026-01-09T14:57:39.232188Z"
                writerId: gmg48429614t9izr64056ihoezcoxhwv
        m: []
        python_version: 3.12.3
        t:
            "1":
                - 1
                - 5
                - 11
                - 49
                - 51
                - 53
                - 71
                - 84
                - 98
            "2":
                - 1
                - 5
                - 11
                - 49
                - 51
                - 53
                - 71
                - 84
                - 98
            "3":
                - 16
                - 24
            "4": 3.12.3
            "5": 0.23.1
            "6": 4.57.3
            "12": 0.23.1
            "13": linux-x86_64
lora:
    value:
        bias: none
        lora_alpha: 64
        lora_dropout: 0.05
        r: 32
        target_modules:
            - q_proj
            - k_proj
            - v_proj
            - o_proj
            - gate_proj
            - up_proj
            - down_proj
        task_type: CAUSAL_LM
model:
    value:
        bnb_4bit_compute_dtype: bfloat16
        bnb_4bit_quant_type: nf4
        model_name: Qwen/Qwen3-4B
        use_4bit: false
        use_nested_quant: true
ppo:
    value:
        adap_kl_ctrl: true
        batch_size: 8
        cliprange: 0.2
        cliprange_value: 0.2
        eval_freq: 50
        gradient_accumulation_steps: 4
        init_kl_coef: 0.2
        learning_rate: 5e-06
        log_freq: 10
        max_new_tokens: 8
        max_seq_length: 2048
        mini_batch_size: 2
        num_train_steps: 3000
        output_dir: ./checkpoints/game_ppo_lora
        ppo_epochs: 4
        resume_from: null
        save_freq: 150
        target_kl: 6
        temperature: 0.7
        top_p: 0.9
        use_wandb: true
        vf_coef: 0.1
        wandb_project: game-rl-training
        wandb_run_name: null
trl_ppo_trainer_config:
    value:
        adap_kl_ctrl: true
        backward_batch_size: 8
        batch_size: 8
        cliprange: 0.2
        cliprange_value: 0.2
        compare_steps: 1
        early_stopping: false
        exp_name: train_ppo_lora
        forward_batch_size: null
        gamma: 1
        global_backward_batch_size: 8
        global_batch_size: 8
        gradient_accumulation_steps: 4
        horizon: 10000
        init_kl_coef: 0.2
        is_encoder_decoder: false
        is_peft_model: true
        kl_penalty: kl
        lam: 0.95
        learning_rate: 5e-06
        log_with: wandb
        max_grad_norm: null
        mini_batch_size: 2
        model_name: gpt2
        optimize_cuda_cache: null
        optimize_device_cache: false
        ppo_epochs: 4
        query_dataset: imdb
        ratio_threshold: 10
        remove_unused_columns: true
        reward_model: sentiment-analysis:lvwerra/distilbert-imdb
        score_clip: null
        seed: 0
        steps: 20000
        target: 6
        target_kl: 1
        task_name: null
        total_ppo_epochs: 2500
        tracker_project_name: trl
        use_score_norm: false
        use_score_scaling: false
        vf_coef: 0.1
        whiten_rewards: false
        world_size: 1
