2026-01-09 15:12:32 | INFO | game_rl_training | Loading tokenizer: Qwen/Qwen3-4B
2026-01-09 15:12:33 | INFO | game_rl_training | Loading base model: Qwen/Qwen3-4B
`torch_dtype` is deprecated! Use `dtype` instead!
2026-01-09 15:12:33 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]
2026-01-09 15:12:36 | INFO | game_rl_training | Applying LoRA configuration...
2026-01-09 15:12:39 | INFO | root | peft adapter initialised
2026-01-09 15:12:39 | INFO | game_rl_training | Creating reference model...
2026-01-09 15:12:39 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]
2026-01-09 15:12:41 | WARNING | root | A <class 'transformers.models.qwen3.modeling_qwen3.Qwen3ForCausalLM'> model is loaded from 'Qwen/Qwen3-4B', and no v_head weight is found. This IS expected if you are not resuming PPO training.
2026-01-09 15:12:42 | INFO | game_rl_training | Initializing PPO trainer...
wandb: wandb.init() called while a run is active and reinit is set to 'default', so returning the previous run.
/root/workplace/game_rl_training/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:262: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.
  warnings.warn(
2026-01-09 15:12:42 | INFO | game_rl_training | Using local OpenSpiel execution (in-process inference, no env server, no vLLM).
2026-01-09 15:12:42 | INFO | game_rl_training | Initializing curriculum sampler...
2026-01-09 15:12:42 | INFO | game_rl_training | Setup complete!
2026-01-09 15:12:42 | INFO | game_rl_training | Starting training...
2026-01-09 15:12:42 | INFO | game_rl_training | Step 1/3000: Collecting rollouts...
2026-01-09 15:15:13 | INFO | game_rl_training | Training...
Traceback (most recent call last):
  File "/root/workplace/game_rl_training/train_ppo_lora.py", line 587, in <module>
    main()
  File "/root/workplace/game_rl_training/train_ppo_lora.py", line 583, in main
    asyncio.run(trainer.train())
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/root/workplace/game_rl_training/train_ppo_lora.py", line 451, in train
    stats = self.train_step(rollouts)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/workplace/game_rl_training/train_ppo_lora.py", line 419, in train_step
    stats = self.ppo_trainer.step(batch_queries, batch_responses, batch_rewards)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 81, in inner
    return func(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/workplace/game_rl_training/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py", line 688, in step
    model_inputs = self.prepare_model_inputs(queries, responses)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/workplace/game_rl_training/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py", line 943, in prepare_model_inputs
    input_ids = [torch.cat([q, r]) for q, r in zip(queries, responses)]
                 ^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 2 and 1
