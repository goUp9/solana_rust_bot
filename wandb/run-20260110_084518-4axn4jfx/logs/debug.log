2026-01-10 08:45:18,432 INFO    MainThread:132437 [wandb_setup.py:_flush():80] Current SDK version is 0.23.1
2026-01-10 08:45:18,432 INFO    MainThread:132437 [wandb_setup.py:_flush():80] Configure stats pid to 132437
2026-01-10 08:45:18,432 INFO    MainThread:132437 [wandb_setup.py:_flush():80] Loading settings from /root/.config/wandb/settings
2026-01-10 08:45:18,432 INFO    MainThread:132437 [wandb_setup.py:_flush():80] Loading settings from /root/workplace/game_rl_training/wandb/settings
2026-01-10 08:45:18,432 INFO    MainThread:132437 [wandb_setup.py:_flush():80] Loading settings from environment variables
2026-01-10 08:45:18,432 INFO    MainThread:132437 [wandb_init.py:setup_run_log_directory():714] Logging user logs to /root/workplace/game_rl_training/wandb/run-20260110_084518-4axn4jfx/logs/debug.log
2026-01-10 08:45:18,432 INFO    MainThread:132437 [wandb_init.py:setup_run_log_directory():715] Logging internal logs to /root/workplace/game_rl_training/wandb/run-20260110_084518-4axn4jfx/logs/debug-internal.log
2026-01-10 08:45:18,432 INFO    MainThread:132437 [wandb_init.py:init():841] calling init triggers
2026-01-10 08:45:18,432 INFO    MainThread:132437 [wandb_init.py:init():846] wandb.init called with sweep_config: {}
config: {'model': {'model_name': 'Qwen/Qwen3-4B', 'use_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_type': 'nf4', 'use_nested_quant': True}, 'lora': {'r': 16, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'], 'lora_dropout': 0.05, 'bias': 'none', 'task_type': 'CAUSAL_LM'}, 'ppo': {'batch_size': 4, 'mini_batch_size': 4, 'gradient_accumulation_steps': 1, 'learning_rate': 5e-06, 'ppo_epochs': 1, 'init_kl_coef': 0.001, 'target_kl': 50.0, 'adap_kl_ctrl': False, 'cliprange': 0.3, 'cliprange_value': 0.3, 'vf_coef': 0.1, 'num_train_steps': 500, 'save_freq': 150, 'eval_freq': 50, 'log_freq': 1, 'max_seq_length': 512, 'max_new_tokens': 4, 'temperature': 0.3, 'top_p': 0.9, 'output_dir': './checkpoints/game_ppo_lora', 'resume_from': None, 'use_wandb': True, 'wandb_project': 'game-rl-training', 'wandb_run_name': None}, '_wandb': {}}
2026-01-10 08:45:18,432 INFO    MainThread:132437 [wandb_init.py:init():889] starting backend
2026-01-10 08:45:18,858 INFO    MainThread:132437 [wandb_init.py:init():892] sending inform_init request
2026-01-10 08:45:18,865 INFO    MainThread:132437 [wandb_init.py:init():900] backend started and connected
2026-01-10 08:45:18,867 INFO    MainThread:132437 [wandb_init.py:init():970] updated telemetry
2026-01-10 08:45:18,874 INFO    MainThread:132437 [wandb_init.py:init():994] communicating run to backend with 90.0 second timeout
2026-01-10 08:45:19,703 INFO    MainThread:132437 [wandb_init.py:init():1041] starting run threads in backend
2026-01-10 08:45:19,800 INFO    MainThread:132437 [wandb_run.py:_console_start():2521] atexit reg
2026-01-10 08:45:19,800 INFO    MainThread:132437 [wandb_run.py:_redirect():2369] redirect: wrap_raw
2026-01-10 08:45:19,800 INFO    MainThread:132437 [wandb_run.py:_redirect():2438] Wrapping output streams.
2026-01-10 08:45:19,801 INFO    MainThread:132437 [wandb_run.py:_redirect():2461] Redirects installed.
2026-01-10 08:45:19,803 INFO    MainThread:132437 [wandb_init.py:init():1081] run started, returning control to user process
2026-01-10 08:45:39,767 INFO    MainThread:132437 [wandb_run.py:_config_callback():1396] config_cb None None {'trl_ppo_trainer_config': {'exp_name': 'train_ppo_lora', 'seed': 0, 'log_with': 'wandb', 'task_name': None, 'model_name': 'gpt2', 'query_dataset': 'imdb', 'reward_model': 'sentiment-analysis:lvwerra/distilbert-imdb', 'remove_unused_columns': True, 'tracker_project_name': 'trl', 'steps': 20000, 'learning_rate': 5e-06, 'adap_kl_ctrl': False, 'init_kl_coef': 0.001, 'kl_penalty': 'kl', 'target': 50.0, 'horizon': 10000, 'gamma': 1, 'lam': 0.95, 'cliprange': 0.3, 'cliprange_value': 0.3, 'vf_coef': 0.1, 'batch_size': 4, 'forward_batch_size': None, 'mini_batch_size': 4, 'gradient_accumulation_steps': 1, 'world_size': 1, 'ppo_epochs': 1, 'max_grad_norm': None, 'optimize_cuda_cache': None, 'optimize_device_cache': False, 'early_stopping': False, 'target_kl': 1, 'compare_steps': 1, 'ratio_threshold': 10.0, 'use_score_scaling': True, 'use_score_norm': True, 'score_clip': 10.0, 'whiten_rewards': False, 'is_encoder_decoder': False, 'is_peft_model': True, 'backward_batch_size': 4, 'global_backward_batch_size': 4, 'global_batch_size': 4, 'total_ppo_epochs': 5000}}
