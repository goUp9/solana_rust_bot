2026-01-09 14:50:14 | INFO | game_rl_training | Loading tokenizer: Qwen/Qwen3-4B
2026-01-09 14:50:15 | INFO | game_rl_training | Loading base model: Qwen/Qwen3-4B
`torch_dtype` is deprecated! Use `dtype` instead!
2026-01-09 14:50:16 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.78it/s]
2026-01-09 14:50:18 | INFO | game_rl_training | Applying LoRA configuration...
2026-01-09 14:50:21 | INFO | root | peft adapter initialised
2026-01-09 14:50:21 | INFO | game_rl_training | Creating reference model...
2026-01-09 14:50:21 | INFO | accelerate.utils.modeling | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.78it/s]
2026-01-09 14:50:23 | WARNING | root | A <class 'transformers.models.qwen3.modeling_qwen3.Qwen3ForCausalLM'> model is loaded from 'Qwen/Qwen3-4B', and no v_head weight is found. This IS expected if you are not resuming PPO training.
<string>:167: FutureWarning: The `PPOConfig` is now located in `trl.experimental`. Please update your imports to `from trl.experimental.ppo import PPOConfig`. The current import path will be removed and no longer supported in TRL 0.29. For more information, see https://github.com/huggingface/trl/issues/4223.
2026-01-09 14:50:24 | INFO | game_rl_training | Initializing PPO trainer...
/root/workplace/game_rl_training/train_ppo_lora.py:242: FutureWarning: The `PPOTrainer` is now located in `trl.experimental`. Please update your imports to `from trl.experimental.ppo import PPOTrainer`. The current import path will be removed and no longer supported in TRL 0.29. For more information, see https://github.com/huggingface/trl/issues/4223.
  self.ppo_trainer = PPOTrainer(
Traceback (most recent call last):
  File "/root/workplace/game_rl_training/train_ppo_lora.py", line 560, in <module>
    main()
  File "/root/workplace/game_rl_training/train_ppo_lora.py", line 546, in main
    trainer = GamePPOTrainer(
              ^^^^^^^^^^^^^^^
  File "/root/workplace/game_rl_training/train_ppo_lora.py", line 150, in __init__
    self._setup()
  File "/root/workplace/game_rl_training/train_ppo_lora.py", line 242, in _setup
    self.ppo_trainer = PPOTrainer(
                       ^^^^^^^^^^^
  File "/root/workplace/game_rl_training/venv/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py", line 35, in __init__
    super().__init__(*args, **kwargs)
TypeError: PPOTrainer.__init__() got an unexpected keyword argument 'config'
